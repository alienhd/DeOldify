{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Video Colorization with Sequence-Based Model\n",
    "\n",
    "This notebook demonstrates video colorization using an advanced sequence-based model, conceptually similar to architectures like BiSTNet. Such models consider multiple frames at once to improve temporal consistency and reduce flickering compared to single-frame colorization methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import necessary modules and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE:  This must be the first DeOldify cell to run! Select GPU environment in Colab for best performance.\n",
    "from deoldify import device\n",
    "from deoldify.device_id import DeviceId\n",
    "\n",
    "#Choices: CPU, GPU0...GPU7\n",
    "device.set(device=DeviceId.GPU0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from deoldify.visualize import get_advanced_video_colorizer, show_video_in_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Matplotlib style for dark background, optional\n",
    "plt.style.use('dark_background')\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*?Your .*? set is empty.*?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Advanced Video Colorizer\n",
    "\n",
    "This step loads the sequence-based model. The `n_frames_input` parameter (defaulting to 5 in the model setup) determines how many frames the model considers simultaneously. A higher number can lead to better temporal consistency but may be more computationally intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters like weights_name, render_factor, n_frames_input can be adjusted here if needed,\n",
    "# but we'll use defaults or values passed during get_advanced_video_colorizer setup.\n",
    "colorizer = get_advanced_video_colorizer() \n",
    "# To use specific weights or model parameters (if future models allow):\n",
    "# colorizer = get_advanced_video_colorizer(weights_name='MyAdvancedModel.pth', n_frames_input=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug Visualizations Setup\n",
    "The following cells help visualize various stages of the colorization process for a deeper understanding and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image as PilImage\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from fastai.vision.image import Image as FastAIImage \n",
    "from fastai.vision import transform as vision_transform \n",
    "\n",
    "def show_images_row(imgs_with_titles, main_title='', fig_size=(15, 5)):\n",
    "    num_imgs = len(imgs_with_titles)\n",
    "    if num_imgs == 0:\n",
    "        print(\"No images to display.\")\n",
    "        return\n",
    "    fig, axes = plt.subplots(1, num_imgs, figsize=fig_size)\n",
    "    if num_imgs == 1:\n",
    "        axes = [axes] \n",
    "    for ax, (img, title) in zip(axes, imgs_with_titles):\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            img = vision_transform.ToPILImage()(img.cpu())\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "    fig.suptitle(main_title, fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "This notebook is primarily set up for processing local video files. You can also process videos from URLs.\n",
    "\n",
    "### For Local Files (Recommended for Debugging Visualizations):\n",
    "1. Upload your video file to the `video/source/` directory in your Colab/Jupyter environment.\n",
    "2. In the **\"Colorize Video!\"** cell below, ensure `source_url` is set to `None`.\n",
    "3. Set `file_name_with_ext` in that same cell to the exact name of your uploaded video file (e.g., 'my_local_video.mp4').\n",
    "\n",
    "### `file_name_stem` (Used for naming output directories and files):\n",
    "   - If processing a local file, the `file_name_stem` is automatically derived from `file_name_with_ext` (e.g., 'my_local_video' from 'my_local_video.mp4'). This stem is used for creating directories in `video/bwframes/` and `video/colorframes/`.\n",
    "   - If processing from a URL, you'll define a `file_name_stem_for_url` which will be used for the downloaded and processed files.\n",
    "\n",
    "### `source_url` (Optional):\n",
    "   - To process a video from a URL (e.g., YouTube), uncomment the URL-related lines in the **\"Colorize Video!\"** cell and set `source_url` to the video's web address. Provide a `file_name_stem_for_url`.\n",
    "\n",
    "### `render_factor`:\n",
    "   - Determines the resolution at which the colorization model processes the video. Lower values (e.g., 21) render faster, and colors might appear more vibrant. Higher values can be better for high-quality input but may wash out colors slightly. Default is 21. Max is ~44 on 11GB GPUs.\n",
    "\n",
    "### `result_path`:\n",
    "   - This will be automatically determined. The final colorized video will be in the `video/result/` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colorize Video!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LOCAL FILE PROCESSING (Primary Example) ---\n",
    "source_url = None \n",
    "# 1. Upload your video to the 'video/source/' directory.\n",
    "# 2. Set file_name_with_ext to the exact name of your uploaded video file.\n",
    "file_name_with_ext = 'my_local_video.mp4' # IMPORTANT: Change this to your uploaded video's name\n",
    "\n",
    "render_factor = 21 # Default render_factor. Adjust if needed.\n",
    "\n",
    "# --- Optional: URL PROCESSING ---\n",
    "# To use a URL, comment out the local file section above, and uncomment the lines below.\n",
    "# source_url = 'https://www.youtube.com/watch?v=your_video_id_here' # Replace with a real video URL\n",
    "# file_name_stem_for_url = 'my_url_video' # Base name for downloaded/output files\n",
    "\n",
    "result_path = None\n",
    "file_name_stem = None # Will be set based on the processing path\n",
    "\n",
    "if source_url is not None:\n",
    "    print(f\"Attempting to colorize video from URL: {source_url}\")\n",
    "    file_name_stem = file_name_stem_for_url # Use the user-defined stem for URL processing\n",
    "    result_path = colorizer.colorize_from_url(source_url, base_file_name=file_name_stem, render_factor=render_factor)\n",
    "    if result_path and os.path.exists(result_path):\n",
    "        print(f\"Colorized video saved to: {result_path}\")\n",
    "        show_video_in_notebook(result_path)\n",
    "    else:\n",
    "        print(f\"Colorization from URL failed or result_path is not valid: {result_path}\")\n",
    "elif file_name_with_ext: # Local file processing\n",
    "    print(f\"Attempting to colorize local file: video/source/{file_name_with_ext}\")\n",
    "    file_name_stem = Path(file_name_with_ext).stem \n",
    "    source_video_path = Path('./video/source') / file_name_with_ext\n",
    "    if not source_video_path.exists():\n",
    "        print(f\"ERROR: Source video not found at {source_video_path}. Please upload the video and try again.\")\n",
    "    else:\n",
    "        result_path = colorizer.colorize_from_file_name(file_name_with_ext, render_factor=render_factor)\n",
    "        if result_path and os.path.exists(result_path):\n",
    "            print(f\"Colorized video saved to: {result_path}\")\n",
    "            show_video_in_notebook(result_path)\n",
    "        else:\n",
    "            print(f\"Colorization of local file failed or result_path is not valid: {result_path}\")\n",
    "else:\n",
    "    print(\"Please set `file_name_with_ext` for local file processing or provide and uncomment a `source_url`.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --- Debug Visualizations ---\n",
    "The cells below are for inspecting the intermediate results of the video colorization process. \n",
    "**Important:** You must first run the \"Colorize Video!\" cell above to generate the necessary frame data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Video for Frame Inspection\n",
    "This cell sets the `file_name_stem_for_inspection` variable. It should match the `file_name_stem` derived from the video processed in the \"Colorize Video!\" cell. If you processed a local file named `my_video.mp4`, then `file_name_stem` would be `my_video`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This variable should match the 'file_name_stem' from the video you just processed.\n",
    "if 'file_name_stem' in locals() and file_name_stem:\n",
    "    file_name_stem_for_inspection = file_name_stem\n",
    "else:\n",
    "    # Fallback if file_name_stem was not set (e.g., if colorization cell was not run or failed early)\n",
    "    file_name_stem_for_inspection = 'my_local_video' # Replace with your default if needed\n",
    "    print(f\"Warning: 'file_name_stem' was not found from the colorization cell. Defaulting to '{file_name_stem_for_inspection}'. Ensure this directory exists in video/bwframes/ and video/colorframes/.\")\n",
    "\n",
    "print(f\"Using file_name_stem_for_inspection: '{file_name_stem_for_inspection}' for debug visualizations.\")\n",
    "\n",
    "# Define root paths for black & white (bwframes) and colorized (colorframes) frames\n",
    "bw_frames_root = Path('./video/bwframes')\n",
    "color_frames_root = Path('./video/colorframes')\n",
    "\n",
    "# Construct full paths to the specific video's frame directories\n",
    "bw_frames_dir = bw_frames_root / file_name_stem_for_inspection\n",
    "color_frames_dir = color_frames_root / file_name_stem_for_inspection\n",
    "\n",
    "# Frame number to display (e.g., '00001.jpg'). Change as needed.\n",
    "frame_to_show_name = '00001.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Grayscale vs. Colorized Frame\n",
    "Compares a selected original grayscale frame with its colorized version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_frame_path = bw_frames_dir / frame_to_show_name\n",
    "colorized_frame_path = color_frames_dir / frame_to_show_name\n",
    "\n",
    "imgs_to_display = []\n",
    "if original_frame_path.exists():\n",
    "    imgs_to_display.append((PilImage.open(original_frame_path), f'Original BW ({frame_to_show_name})'))\n",
    "else:\n",
    "    print(f'Original frame not found: {original_frame_path}')\n",
    "\n",
    "if colorized_frame_path.exists():\n",
    "    imgs_to_display.append((PilImage.open(colorized_frame_path), f'Colorized ({frame_to_show_name})'))\n",
    "else:\n",
    "    print(f'Colorized frame not found: {colorized_frame_path}')\n",
    "\n",
    "if imgs_to_display:\n",
    "    show_images_row(imgs_to_display, 'Original vs. Colorized Frame Comparison')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize L, A, B Channels\n",
    "Shows the individual L (Luminance), A (Green-Red), and B (Blue-Yellow) channels of a colorized frame. The A and B channels are visualized as grayscale images representing the intensity of color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if colorized_frame_path.exists(): # Uses colorized_frame_path from the cell above\n",
    "    color_pil = PilImage.open(colorized_frame_path)\n",
    "    lab_pil = color_pil.convert('LAB')\n",
    "    l_pil, a_pil, b_pil = lab_pil.split()\n",
    "\n",
    "    imgs_to_display_lab = [\n",
    "        (color_pil, 'Colorized Original'),\n",
    "        (l_pil, 'L Channel'),\n",
    "        (a_pil, 'A Channel (Grayscale)'),\n",
    "        (b_pil, 'B Channel (Grayscale)')\n",
    "    ]\n",
    "    show_images_row(imgs_to_display_lab, 'L, A, B Channel Visualization', fig_size=(20,5))\n",
    "else:\n",
    "    print(f'Colorized frame not found for LAB analysis: {colorized_frame_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Input Sequence to Model (Conceptual)\n",
    "Displays a sequence of grayscale frames that would be fed to the sequence-based model. The model uses such sequences to colorize the middle frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames_for_model = colorizer.vis.filter.n_frames_input if hasattr(colorizer.vis.filter, 'n_frames_input') else 5\n",
    "center_frame_file_idx = -1\n",
    "imgs_sequence = []\n",
    "\n",
    "if bw_frames_dir.exists():\n",
    "    frame_files = sorted([f for f in os.listdir(bw_frames_dir) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "    if not frame_files:\n",
    "        print(f\"No frames found in {bw_frames_dir}\")\n",
    "    else:\n",
    "        try:\n",
    "            center_frame_file_idx = frame_files.index(frame_to_show_name)\n",
    "        except ValueError:\n",
    "            print(f\"Frame {frame_to_show_name} not found in {bw_frames_dir}. Defaulting to a frame near the middle if possible.\")\n",
    "            center_frame_file_idx = len(frame_files) // 2\n",
    "\n",
    "        half_seq = n_frames_for_model // 2\n",
    "        seq_start_file_idx = max(0, center_frame_file_idx - half_seq)\n",
    "        seq_start_file_idx = min(seq_start_file_idx, len(frame_files) - n_frames_for_model)\n",
    "        seq_start_file_idx = max(0, seq_start_file_idx) \n",
    "        seq_end_file_idx = seq_start_file_idx + n_frames_for_model\n",
    "\n",
    "        if len(frame_files) >= n_frames_for_model and seq_end_file_idx <= len(frame_files):\n",
    "            for i in range(seq_start_file_idx, seq_end_file_idx):\n",
    "                frame_path = bw_frames_dir / frame_files[i]\n",
    "                if frame_path.exists():\n",
    "                    title = f'Seq F{i-seq_start_file_idx+1} ({frame_files[i]})'\n",
    "                    if i == center_frame_file_idx:\n",
    "                        title = f'**CENTER** {title}'\n",
    "                    imgs_sequence.append((PilImage.open(frame_path).convert('L'), title))\n",
    "                else:\n",
    "                    print(f'Frame {frame_files[i]} not found for sequence.')\n",
    "                    imgs_sequence = [] \n",
    "                    break\n",
    "            if len(imgs_sequence) == n_frames_for_model:\n",
    "                show_images_row(imgs_sequence, f'Example Grayscale Input Sequence (Model sees {n_frames_for_model} frames)', fig_size=(n_frames_for_model * 3, 3))\n",
    "        else:\n",
    "            center_frame_name_for_print = frame_files[center_frame_file_idx] if center_frame_file_idx >=0 and center_frame_file_idx < len(frame_files) else frame_to_show_name\n",
    "            print(f'Not enough frames in {bw_frames_dir} (found {len(frame_files)}, need {n_frames_for_model}) to display sequence around frame {center_frame_name_for_print}.')\n",
    "else:\n",
    "    print(f\"Directory with BW frames not found: {bw_frames_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Model's AB Output Contribution (Conceptual)\n",
    "This cell attempts to show only the color information (AB channels) produced by the model by applying it to a neutral gray L channel. This helps to isolate what color data the model is generating for the middle frame of a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if colorized_frame_path.exists(): \n",
    "    color_pil = PilImage.open(colorized_frame_path)\n",
    "    lab_pil = color_pil.convert('LAB')\n",
    "    _, a_pil, b_pil = lab_pil.split()\n",
    "\n",
    "    gray_l_channel = PilImage.new('L', color_pil.size, color=128)\n",
    "    \n",
    "    model_color_contribution = PilImage.merge('LAB', (gray_l_channel, a_pil, b_pil)).convert('RGB')\n",
    "\n",
    "    imgs_to_display_ab = [\n",
    "        (color_pil, 'Full Colorized Frame'),\n",
    "        (model_color_contribution, 'Model AB on Neutral L')\n",
    "    ]\n",
    "    show_images_row(imgs_to_display_ab, 'Visualizing Model Color (AB) Contribution')\n",
    "else:\n",
    "    print(f'Colorized frame not found for AB contribution analysis: {colorized_frame_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion & Comparison\n",
    "\n",
    "The sequence-based model used here is designed to produce more temporally stable colorization with reduced flickering compared to models that process each frame independently. \n",
    "\n",
    "Consider colorizing the same video using the original `VideoColorizer.ipynb` (which uses a single-frame model) and compare the results. Pay attention to:\n",
    "- Flickering in areas that should have consistent color.\n",
    "- Color consistency of moving objects.\n",
    "\n",
    "Note: The actual visual improvement depends heavily on the underlying model architecture and training. This notebook provides the *framework* for using such advanced models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame Preview (Optional)\n",
    "\n",
    "The `plot_transformed_image` function visualizes how a single frame is colorized. When used with the `VideoColorizerFilter`, this shows the result of its single-image processing mode (which duplicates the frame to form a sequence). This preview might not fully represent the temporal benefits seen in the full video but can be useful for checking general color quality for a given `render_factor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This uses the .P() method of the filter, which for VideoColorizerFilter duplicates the frame.\n",
    "# Ensure you have processed a video first so that 'bwframes' are available, or provide a direct image path.\n",
    "\n",
    "if 'file_name_stem_for_inspection' in locals() and file_name_stem_for_inspection and 'frame_to_show_name' in locals() and frame_to_show_name:\n",
    "    preview_frame_path = bw_frames_dir / frame_to_show_name # Uses bw_frames_dir from a cell above\n",
    "    if preview_frame_path.exists():\n",
    "        print(f\"Displaying preview for: {preview_frame_path}\")\n",
    "        colorizer.vis.plot_transformed_image(str(preview_frame_path), render_factor=render_factor, display_render_factor=True, figsize=(8,8))\n",
    "    else:\n",
    "        print(f\"Preview frame {preview_frame_path} not found. Ensure video was processed and file_name_stem_for_inspection is correct.\")\n",
    "else:\n",
    "    print(\"Variables 'file_name_stem_for_inspection' or 'frame_to_show_name' are not set. Ensure the colorization and inspection setup cells were run.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "67px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
