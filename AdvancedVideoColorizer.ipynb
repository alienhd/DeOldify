{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Video Colorization with Sequence-Based Model\n",
    "\n",
    "This notebook demonstrates video colorization using an advanced sequence-based model, conceptually similar to architectures like BiSTNet. Such models consider multiple frames at once to improve temporal consistency and reduce flickering compared to single-frame colorization methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import necessary modules and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE:  This must be the first DeOldify cell to run! Select GPU environment in Colab for best performance.\n",
    "from deoldify import device\n",
    "from deoldify.device_id import DeviceId\n",
    "\n",
    "#Choices: CPU, GPU0...GPU7\n",
    "device.set(device=DeviceId.GPU0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from deoldify.visualize import get_advanced_video_colorizer, show_video_in_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Matplotlib style for dark background, optional\n",
    "plt.style.use('dark_background')\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*?Your .*? set is empty.*?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Advanced Video Colorizer\n",
    "\n",
    "This step loads the sequence-based model. The `n_frames_input` parameter (defaulting to 5 in the model setup) determines how many frames the model considers simultaneously. A higher number can lead to better temporal consistency but may be more computationally intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters like weights_name, render_factor, n_frames_input can be adjusted here if needed,\n",
    "# but we'll use defaults or values passed during get_advanced_video_colorizer setup.\n",
    "colorizer = get_advanced_video_colorizer() \n",
    "# To use specific weights or model parameters (if future models allow):\n",
    "# colorizer = get_advanced_video_colorizer(weights_name='MyAdvancedModel.pth', n_frames_input=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "### `source_url`\n",
    "Link to a video from YouTube, Imgur, Twitter, Reddit, Vimeo, etc. GIFs also work. Full list: [youtube-dl supported sites](https://ytdl-org.github.io/youtube-dl/supportedsites.html).\n",
    "To use your own video, set `source_url = None` and upload your file to the `video/source/` directory in your Jupyter environment. Ensure `file_name` matches your uploaded file.\n",
    "\n",
    "### `file_name` (Base name for the video output, without extension)\n",
    "A sensible base name for your video. If using `source_url`, this will be the prefix for the downloaded and output files. If `source_url` is `None`, this should match the stem of your uploaded file in `video/source/`.\n",
    "\n",
    "### `render_factor`\n",
    "Determines the resolution at which the colorization model processes the video. Lower values render faster, and colors might appear more vibrant. Higher values can be better for high-quality input but may wash out colors slightly. The default is 21. Max is ~44 on 11GB GPUs.\n",
    "\n",
    "### `result_path`\n",
    "This will be automatically determined. The final colorized video will be in the `video/result/` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colorize Video!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default render_factor is 21. Adjust if needed.\n",
    "render_factor = 21 \n",
    "\n",
    "# Example using a URL:\n",
    "source_url = 'https://www.youtube.com/watch?v=your_video_id_here' # Replace with a real video URL\n",
    "# Base name for the output video file (without extension)\n",
    "file_name_stem = 'my_advanced_colorized_video'\n",
    "\n",
    "# To use a local file instead:\n",
    "# source_url = None \n",
    "# file_name_stem = 'my_local_video' # Assuming 'my_local_video.mp4' or similar is in video/source/\n",
    "\n",
    "if source_url is not None:\n",
    "    # For URL processing, colorize_from_url now expects a base_file_name (stem)\n",
    "    result_path = colorizer.colorize_from_url(source_url, base_file_name=file_name_stem, render_factor=render_factor)\n",
    "else:\n",
    "    # For local file processing, colorize_from_file_name expects the full name with extension\n",
    "    # User needs to ensure the file_name_with_ext exists in video/source/\n",
    "    file_name_with_ext = file_name_stem + '.mp4' # User should adjust extension if not mp4\n",
    "    print(f\"Attempting to colorize local file: video/source/{file_name_with_ext}\")\n",
    "    result_path = colorizer.colorize_from_file_name(file_name_with_ext, render_factor=render_factor)\n",
    "\n",
    "print(f\"Colorized video saved to: {result_path}\")\n",
    "show_video_in_notebook(result_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion & Comparison\n",
    "\n",
    "The sequence-based model used here is designed to produce more temporally stable colorization with reduced flickering compared to models that process each frame independently. \n",
    "\n",
    "Consider colorizing the same video using the original `VideoColorizer.ipynb` (which uses a single-frame model) and compare the results. Pay attention to:\n",
    "- Flickering in areas that should have consistent color.\n",
    "- Color consistency of moving objects.\n",
    "\n",
    "Note: The actual visual improvement depends heavily on the underlying model architecture and training. This notebook provides the *framework* for using such advanced models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame Preview (Optional)\n",
    "\n",
    "The `plot_transformed_image` function visualizes how a single frame is colorized. When used with the `VideoColorizerFilter`, this shows the result of its single-image processing mode (which duplicates the frame to form a sequence). This preview might not fully represent the temporal benefits seen in the full video but can be useful for checking general color quality for a given `render_factor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This uses the .P() method of the filter, which for VideoColorizerFilter duplicates the frame.\n",
    "# Ensure you have processed a video first so that 'bwframes' are available, or provide a direct image path.\n",
    "\n",
    "# Example: if you ran the cell above with file_name_stem = 'my_advanced_colorized_video'\n",
    "# and it downloaded and extracted frames, you might find a frame like:\n",
    "# 'video/bwframes/my_advanced_colorized_video_downloaded_from_url_ HASH /00001.jpg'\n",
    "# The exact path will depend on how VideoProcessor names the frame extraction folder.\n",
    "# Let's assume a known local image for a stable example:\n",
    "# colorizer.vis.plot_transformed_image('path_to_your_test_image.jpg', render_factor=21, display_render_factor=True, figsize=(8,8))\n",
    "\n",
    "print(\"Frame preview for sequence models shows single-frame duplication behavior.\")\n",
    "print(\"To test frame previews, ensure 'video/bwframes/<file_name_stem>/00001.jpg' exists from a previous run, or point to a valid image.\")\n",
    "# Example, if 'my_advanced_colorized_video' was processed:\n",
    "# frame_preview_path = 'video/bwframes/' + file_name_stem + '/00001.jpg' \n",
    "# if os.path.exists(frame_preview_path):\n",
    "#   colorizer.vis.plot_transformed_image(frame_preview_path, render_factor=21, display_render_factor=True, figsize=(8,8))\n",
    "# else:\n",
    "#   print(f\"Preview frame {frame_preview_path} not found. Run video colorization first or provide a direct image path.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
